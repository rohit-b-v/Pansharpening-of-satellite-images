# -*- coding: utf-8 -*-
"""Basic_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cNQkFW4aJ98QCNrcRaNCjBlH6olBilgE
"""

import cv2
import gc
import glob
import numpy as np
!pip install rasterio
import rasterio
import tensorflow
from keras.models import Input, Model
from keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam

from google.colab.patches import cv2_imshow

import scipy.io

def training_image_creation(img_ms, img_pan, n_factor):


    blurred_img_ms = np.zeros((img_ms.shape))

    for i in range(img_ms.shape[2]):
        blurred_img_ms[:, :, i] = cv2.GaussianBlur(img_ms[:, :, i], (5, 5), 0)

    blurred_img_ms_small = cv2.resize(blurred_img_ms, (int(img_ms.shape[1] / n_factor), int(img_ms.shape[0] / n_factor)),
                                      interpolation = cv2.INTER_AREA)
    blurred_img_ms_sam = cv2.resize(blurred_img_ms_small, (img_ms.shape[1], img_ms.shape[0]), interpolation = cv2.INTER_CUBIC)

    downsampled_img_pan = cv2.resize(img_pan, (img_ms.shape[1], img_ms.shape[0]),
                                     interpolation = cv2.INTER_AREA)[:, :, np.newaxis]

    training_sample_array = np.concatenate((blurred_img_ms_sam, downsampled_img_pan), axis = 2)

    return training_sample_array

def image_clip_to_segment(image_ms_array, train_image_array, image_height_size, image_width_size, percentage_overlap,
                          buffer):


    y_size = ((image_ms_array.shape[0] // image_height_size) + 1) * image_height_size
    y_pad = int(y_size - image_ms_array.shape[0])
    x_size = ((image_ms_array.shape[1] // image_width_size) + 1) * image_width_size
    x_pad = int(x_size - image_ms_array.shape[1])

    img_complete = np.pad(image_ms_array, ((0, y_pad), (0, x_pad), (0, 0)), mode = 'symmetric').astype(image_ms_array.dtype)
    train_complete = np.pad(train_image_array, ((0, y_pad), (0, x_pad), (0, 0)),
                            mode = 'symmetric').astype(train_image_array.dtype)

    img_list = []
    train_list = []

    for i in range(0, int(img_complete.shape[0] - (2 - buffer) * image_height_size),
                   int((1 - percentage_overlap) * image_height_size)):
        for j in range(0, int(img_complete.shape[1] - (2 - buffer) * image_width_size),
                       int((1 - percentage_overlap) * image_width_size)):
            img_original = img_complete[i : i + image_height_size, j : j + image_width_size, 0 : image_ms_array.shape[2]]
            img_list.append(img_original)
            train_original = train_complete[i : i + image_height_size, j : j + image_width_size, :]
            train_list.append(train_original)

    image_segment_array = np.zeros((len(img_list), image_height_size, image_width_size, image_ms_array.shape[2]))
    train_segment_array = np.zeros((len(train_list), image_height_size, image_width_size, train_image_array.shape[2]))

    for index in range(len(img_list)):
        image_segment_array[index] = img_list[index]
        train_segment_array[index] = train_list[index]

    return train_segment_array, image_segment_array

def training_data_generation(DATA_DIR, img_height_size, img_width_size, perc, buff):



    if perc < 0 or perc > 1:
        raise ValueError('Please input a number between 0 and 1 (inclusive) for perc.')

    if buff < 0 or buff > 1:
        raise ValueError('Please input a number between 0 and 1 (inclusive) for buff.')

    img_MS_files = glob.glob('mst*.png')
    img_PAN_files = glob.glob('pant*.tif')

    img_array_list = []
    train_array_list = []

    for file in range(7):

        switch = {
            0:'a',
            1:'b',
            2:'c',
            3:'d',
            4:'f',
            5:'r',
            6:'u'
        }
        with rasterio.open('mst'+switch[file]+'.png') as f:
            metadata = f.profile
            ms_img = np.transpose(f.read(tuple(np.arange(metadata['count']) + 1)), [1, 2, 0])
        with rasterio.open('pant'+switch[file]+'.png') as g:
            metadata_pan = g.profile
            pan_img = g.read(1)

        ms_to_pan_ratio = metadata['transform'][0] / metadata_pan['transform'][0]

        train_img = training_image_creation(ms_img, pan_img, n_factor = ms_to_pan_ratio)

        train_array, img_array = image_clip_to_segment(ms_img, train_img, img_height_size, img_width_size,
                                                       percentage_overlap = perc, buffer = buff)

        img_array_list.append(img_array)
        train_array_list.append(train_array)

    img_full_array = np.concatenate(img_array_list, axis = 0)
    train_full_array = np.concatenate(train_array_list, axis = 0)

    del img_MS_files, img_PAN_files
    gc.collect()

    return train_full_array, img_full_array

def pcnn_model(image_height_size, image_width_size, n_bands, n1 = 64, n2 = 32, f1 = 9, f2 = 5, f3 = 5, l_r = 0.0001):


    img_input = Input(shape = (image_height_size, image_width_size, n_bands))
    conv = Conv2D(128,(11,11),padding = 'same',activation = 'relu')(img_input)
    conv1 = Conv2D(n1, (f1, f1), padding = 'same', activation = 'relu')(conv)
    conv2 = Conv2D(n2, (f2, f2), padding = 'same', activation = 'relu')(conv1)
    conv3 = Conv2D(n_bands - 1, (f3, f3), padding = 'same')(conv2)

    model = Model(inputs = img_input, outputs = conv3)
    model.compile(optimizer = Adam(lr = l_r), loss = 'mse', metrics = ['mse', 'accuracy'])

    return model

train_full_array, img_full_array = training_data_generation('x', 64, 64, 0.5, 0.5)

model = pcnn_model(64,64,4)

print(model.summary())

history = model.fit(train_full_array, img_full_array,
          batch_size=1,
          epochs=20,
          verbose=1)

import matplotlib.pyplot as plt

plt.plot(history.history['loss'])
# plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

plt.plot(history.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

def image_model_predict(input_ms_image_filename, input_pan_image_filename, output_filename,
                        img_height_size, img_width_size, fitted_model,
                        percentage_overlap, write):



    with rasterio.open(input_ms_image_filename) as f:
        metadata = f.profile
        ms_img = np.transpose(f.read(tuple(np.arange(metadata['count']) + 1)), [1, 2, 0])

    with rasterio.open(input_pan_image_filename) as g:
        metadata_pan = g.profile
        pan_img = np.expand_dims(g.read(1), axis = 2)

    ms_to_pan_ratio = metadata['transform'][0] / metadata_pan['transform'][0]
    ms_img_upsampled = cv2.resize(ms_img, (int(ms_img.shape[1] * ms_to_pan_ratio), int(ms_img.shape[0] * ms_to_pan_ratio)),
                                  interpolation = cv2.INTER_CUBIC)
    pred_stack = np.concatenate((ms_img_upsampled, pan_img), axis = 2)


    y_size = ((pred_stack.shape[0] // img_height_size) + 1) * img_height_size
    y_pad = int(y_size - pred_stack.shape[0])
    x_size = ((pred_stack.shape[1] // img_width_size) + 1) * img_width_size
    x_pad = int(x_size - pred_stack.shape[1])

    img_complete = np.pad(pred_stack, ((0, y_pad), (0, x_pad), (0, 0)), mode = 'symmetric').astype(pred_stack.dtype)

    pred_img = np.zeros((img_complete.shape[0], img_complete.shape[1], ms_img.shape[2]))
    weight_mask = np.zeros((img_complete.shape[0], img_complete.shape[1], 1))
    img_holder = np.zeros((1, img_height_size, img_width_size, img_complete.shape[2]))


    for i in range(0, img_complete.shape[0] - img_height_size + 1, int((1 - percentage_overlap) * img_height_size)):
        for j in range(0, img_complete.shape[1] - img_width_size + 1, int((1 - percentage_overlap) * img_width_size)):
            img_holder[0] = img_complete[i : (i + img_height_size), j : (j + img_width_size), 0 : pred_stack.shape[2]]
            preds = fitted_model.predict(img_holder)
            pred_img[i : i + img_height_size, j : j + img_width_size, :] += preds[0, :, :, :]
            weight_mask[i : i + img_height_size, j : j + img_width_size, 0] += 1

    pred_img_complete = pred_img[0 : pan_img.shape[0], 0 : pan_img.shape[1], :]
    weight_mask_complete = weight_mask[0 : pan_img.shape[0], 0 : pan_img.shape[1], 0][:, :, np.newaxis]
    pred_img_final = (pred_img_complete / weight_mask_complete).astype(metadata['dtype'])


    metadata_pan['count'] = ms_img_upsampled.shape[2]
    with rasterio.open(output_filename, 'w', **metadata_pan) as dst:
        dst.write(np.transpose(pred_img_final, [2, 0, 1]))

    return pred_img_final

fin = image_model_predict('mstz.png','pantz.png','out.png',64,64,model,0,1)

ms = cv2.imread('mstz.png')
image_rgb = cv2.cvtColor(ms, cv2.COLOR_BGR2RGB)
plt.imshow(image_rgb)
plt.show()
pan = cv2.imread('pantz.png')
image_rgb2 = cv2.cvtColor(pan, cv2.COLOR_BGR2RGB)
plt.imshow(image_rgb2)
plt.show()
plt.imshow(fin)
plt.show()

