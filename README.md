# Pansharpening-of-satellite-images
Development of Automatic Land Cover Change Detection and Analysis System from High-Resolution Remote Sensing Images

This project focuses on developing an automatic land cover change detection and analysis system using high-resolution remote sensing images, with a specific emphasis on the technique of pansharpening. Pansharpening is a widely used image fusion technique aimed at enhancing the spatial resolution of multispectral satellite imagery by integrating it with high-resolution panchromatic images. A literature survey of various traditional and deep learning-based pansharpening methods highlights the evolution of this technique. Non-deep learning methods such as Brovey and ESRI transformations have been used historically, but often suffer from inefficiencies and inaccuracies in varying datasets. In contrast, modern approaches, including convolutional neural networks (CNNs) and autoencoders, have improved the accuracy and adaptability of pansharpening models, although some still struggle with effective feature extraction or image reconstruction in all regions.

The data used in this project consists of multispectral images with dimensions 512x512x3 and panchromatic images with dimensions 512x512. These images undergo preprocessing involving calculation of scaling factors, Gaussian blurring for interpolation, and spatial downsampling. The preprocessed images are split into smaller 64x64 patches for efficient model training. The proposed base model comprises three blocks: the first for extracting features from multispectral images, the second for capturing spatial features from panchromatic images, and the third for fusing outputs from both sources to produce a high-resolution pansharpened image. Each block is composed of convolutional and pooling layers, and the model is trained using Mean Squared Error loss with the Adam optimizer. The Swish activation function is employed to introduce non-linearity in the model.